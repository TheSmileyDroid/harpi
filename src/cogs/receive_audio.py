"""M√≥dulo para gravar √°udio dos canais de voz do Discord."""

import asyncio
import io
import json
import logging
import os
import wave
import zipfile
from typing import Any, Dict, Optional, cast

import discord
import discord.ext
from discord import File, Message, TextChannel, VoiceClient
from discord.ext import commands
from discord.sinks import WaveSink
from vosk import KaldiRecognizer, Model

logger = logging.getLogger(__name__)


class ReceiveAudioCog(commands.Cog):
    """Cog respons√°vel pela grava√ß√£o de √°udio dos canais de voz."""

    def __init__(self, bot: commands.Bot) -> None:
        """Inicializa o cog de grava√ß√£o de √°udio.

        Args:
            bot: Bot do Discord ao qual este cog ser√° anexado.
        """
        self.bot = bot
        self.connections: Dict[int, VoiceClient] = {}
        self.transcription_messages: Dict[
            str, Message
        ] = {}  # Armazena mensagens para atualiza√ß√£o
        self.vosk_model_path = "models/vosk-model-small-pt-0.3"
        self.vosk_zip_path = f"{self.vosk_model_path}.zip"
        self._setup_logger()
        self._setup_vosk_model()

    def _setup_vosk_model(self) -> None:
        """Prepara o modelo Vosk para reconhecimento de fala em portugu√™s."""
        try:
            # Verifica se o modelo j√° est√° extra√≠do
            if not os.path.exists(self.vosk_model_path):
                logger.info(f"Extraindo modelo Vosk de {self.vosk_zip_path}")
                # Cria o diret√≥rio models se n√£o existir
                os.makedirs("models", exist_ok=True)

                # Extrai o arquivo zip
                with zipfile.ZipFile(self.vosk_zip_path, "r") as zip_ref:
                    zip_ref.extractall("models")
                logger.info("Modelo Vosk extra√≠do com sucesso")
            else:
                logger.info("Modelo Vosk j√° existe, pulando extra√ß√£o")
        except Exception as e:
            logger.error(f"Erro ao configurar modelo Vosk: {e}")

    def _setup_logger(self) -> None:
        """Configura o logger para este m√≥dulo."""
        logger.setLevel(logging.INFO)
        if not logger.handlers:
            handler = logging.StreamHandler()
            handler.setFormatter(
                logging.Formatter(
                    "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
                )
            )
            logger.addHandler(handler)

    async def transcribe_audio(self, audio_file: io.BytesIO) -> str:
        """Transcreve um arquivo de √°udio para texto usando o modelo Vosk.

        Args:
            audio_file: Arquivo de √°udio a ser transcrito.

        Returns:
            Texto transcrito do √°udio.
        """
        try:
            # Carrega o modelo Vosk para portugu√™s
            model = Model(self.vosk_model_path)

            # Abre o arquivo de √°udio
            wf = wave.open(audio_file, "rb")

            # Configura o reconhecedor
            recognizer = KaldiRecognizer(model, wf.getframerate())
            recognizer.SetWords(True)

            # Processa o √°udio em chunks
            results = []
            chunk_size = 4000  # tamanho do chunk em bytes

            while True:
                data = wf.readframes(chunk_size)
                if len(data) == 0:
                    break

                if recognizer.AcceptWaveform(data):
                    result = json.loads(recognizer.Result())
                    if "text" in result and result["text"]:
                        results.append(result["text"])

            # Obt√©m o resultado final
            final_result = json.loads(recognizer.FinalResult())
            if "text" in final_result and final_result["text"]:
                results.append(final_result["text"])

            # Junta todos os resultados
            transcription = " ".join(results)

            return (
                transcription if transcription else "Nenhum texto reconhecido."
            )

        except Exception as e:
            logger.error(f"Erro ao transcrever √°udio: {e}")
            return f"Erro na transcri√ß√£o: {str(e)}"

    async def transcribe_audio_live(
        self, audio_file: io.BytesIO, channel: TextChannel, user_id: str
    ) -> str:
        """Transcreve √°udio em tempo real, atualizando uma mensagem no Discord.

        Args:
            audio_file: Arquivo de √°udio a ser transcrito.
            channel: Canal onde a mensagem ser√° enviada/atualizada.
            user_id: ID do usu√°rio cujo √°udio est√° sendo transcrito.

        Returns:
            Texto completo transcrito do √°udio.
        """
        try:
            # Carrega o modelo Vosk para portugu√™s
            model = Model(self.vosk_model_path)

            # Abre o arquivo de √°udio
            wf = wave.open(audio_file, "rb")

            # Configura o reconhecedor
            recognizer = KaldiRecognizer(model, wf.getframerate())
            recognizer.SetWords(True)

            # Inicia com uma mensagem vazia que ser√° atualizada
            message_key = f"{channel.id}_{user_id}"
            if message_key not in self.transcription_messages:
                initial_message = await channel.send(
                    f"üé§ **Transcrevendo √°udio de <@{user_id}>**: _(processando...)_"
                )
                self.transcription_messages[message_key] = initial_message

            # Buffer para acumular a transcri√ß√£o completa
            full_transcription = ""
            segment_buffer = ""

            # Processa o √°udio em chunks
            chunk_size = 4000  # tamanho do chunk em bytes
            update_interval = 0.5  # segundos entre atualiza√ß√µes da mensagem
            last_update = 0
            current_time = 0

            while True:
                data = wf.readframes(chunk_size)
                if len(data) == 0:
                    break

                # Atualiza o tempo atual baseado na taxa de amostragem e tamanho do chunk
                frames_read = (
                    chunk_size / wf.getsampwidth() / wf.getnchannels()
                )
                time_increment = frames_read / wf.getframerate()
                current_time += time_increment

                if recognizer.AcceptWaveform(data):
                    result = json.loads(recognizer.Result())
                    if "text" in result and result["text"]:
                        # Adiciona ao buffer de segmento e √† transcri√ß√£o completa
                        new_text = result["text"]
                        segment_buffer += " " + new_text
                        full_transcription += " " + new_text

                # Atualiza a mensagem periodicamente
                if (
                    current_time - last_update >= update_interval
                    and segment_buffer
                ):
                    message = self.transcription_messages[message_key]
                    await message.edit(
                        content=f"üé§ **Transcrevendo √°udio de <@{user_id}>**: {full_transcription.strip()}"
                    )
                    segment_buffer = ""  # Limpa o buffer de segmento
                    last_update = current_time

            # Processa o resultado final
            final_result = json.loads(recognizer.FinalResult())
            if "text" in final_result and final_result["text"]:
                final_text = final_result["text"]
                full_transcription += " " + final_text

            # Atualiza a mensagem uma √∫ltima vez com o texto completo
            final_transcription = full_transcription.strip()
            if final_transcription:
                message = self.transcription_messages[message_key]
                await message.edit(
                    content=f"üé§ **Transcri√ß√£o de <@{user_id}>**: {final_transcription}"
                )
            else:
                message = self.transcription_messages[message_key]
                await message.edit(
                    content=f"üé§ **Transcri√ß√£o de <@{user_id}>**: _(Nenhum texto reconhecido)_"
                )
                final_transcription = "Nenhum texto reconhecido."

            return final_transcription

        except Exception as e:
            logger.error(f"Erro ao transcrever √°udio em tempo real: {e}")
            error_message = f"Erro na transcri√ß√£o em tempo real: {str(e)}"

            # Tenta atualizar a mensagem com o erro
            message_key = f"{channel.id}_{user_id}"
            if message_key in self.transcription_messages:
                message = self.transcription_messages[message_key]
                await message.edit(
                    content=f"üé§ **Erro na transcri√ß√£o de <@{user_id}>**: {str(e)}"
                )

            return error_message

    @commands.command(name="record")
    async def record(self, ctx: commands.Context) -> None:
        """Inicia a grava√ß√£o de √°udio do canal de voz.

        Args:
            ctx: Contexto do comando.
        """
        # Verifica se o autor do comando est√° em um canal de voz
        if not ctx.author.voice:
            await ctx.send("Voc√™ n√£o est√° em um canal de voz!")
            return

        # Verifica se j√° existe uma grava√ß√£o em andamento no servidor
        if ctx.guild.id in self.connections:
            await ctx.send(
                "J√° existe uma grava√ß√£o em andamento neste servidor!"
            )
            return

        try:
            # Conecta ao canal de voz do autor
            vc = cast(
                discord.VoiceClient, await ctx.author.voice.channel.connect()
            )
            self.connections[ctx.guild.id] = vc

            # Inicia a grava√ß√£o
            vc.start_recording(
                WaveSink(),
                self.once_done,
                ctx.channel,
                sync_start=True,
            )
            await ctx.send("Grava√ß√£o iniciada!")
            logger.info(f"Grava√ß√£o iniciada no servidor {ctx.guild.id}")
        except Exception as e:
            logger.error(f"Erro ao iniciar grava√ß√£o: {e}")
            await ctx.send(f"Erro ao iniciar grava√ß√£o: {e}")

    @commands.command(name="stop_recording")
    async def stop_recording(self, ctx: commands.Context) -> None:
        """Para a grava√ß√£o de √°udio em andamento.

        Args:
            ctx: Contexto do comando.
        """
        guild_id = getattr(ctx.guild, "id", None)
        if not guild_id:
            await ctx.send("Este comando s√≥ pode ser usado em servidores.")
            return

        if guild_id in self.connections:
            try:
                vc = self.connections[guild_id]
                vc.stop_recording()  # Isso chamar√° o callback once_done
                logger.info(f"Grava√ß√£o finalizada no servidor {guild_id}")
                await ctx.send("Grava√ß√£o finalizada!")
            except Exception as e:
                logger.error(f"Erro ao parar grava√ß√£o: {e}")
                await ctx.send(f"Erro ao parar grava√ß√£o: {e}")
        else:
            await ctx.send("N√£o h√° grava√ß√£o em andamento neste servidor.")

    async def once_done(
        self, sink: WaveSink, channel: TextChannel, *args: Any
    ) -> None:
        """Callback chamado quando a grava√ß√£o √© finalizada.

        Args:
            sink: Sink contendo os dados de √°udio gravados.
            channel: Canal de texto onde a mensagem ser√° enviada.
            args: Argumentos adicionais.
        """
        assert isinstance(sink, WaveSink), "O sink deve ser do tipo WaveSink"
        assert isinstance(channel, TextChannel), (
            "O canal deve ser do tipo TextChannel"
        )
        # Obt√©m o ID do servidor a partir da conex√£o de voz
        guild_id: Optional[int] = None
        for gid, vc in self.connections.items():
            if vc == sink.vc:
                guild_id = gid
                break

        if guild_id is not None:
            del self.connections[guild_id]

        # Desconecta do canal de voz
        await sink.vc.disconnect()

        # Prepara os arquivos de √°udio e os usu√°rios gravados
        if not sink.audio_data:
            await channel.send("Nenhum √°udio foi gravado.")
            return

        recorded_users = [
            f"<@{user_id}>" for user_id in sink.audio_data.keys()
        ]

        # Iniciar mensagem de status
        status_message = await channel.send(
            f"üîÑ Processando √°udio de {len(sink.audio_data)} usu√°rios..."
        )

        # Cria arquivos para envio
        files = []
        for user_id, audio in sink.audio_data.items():
            assert isinstance(audio, discord.sinks.AudioData), (
                "O objeto de √°udio deve ser do tipo AudioData"
            )
            assert isinstance(audio.file, io.BytesIO), (
                "O arquivo de √°udio deve ser do tipo BytesIO"
            )

            # Faz uma c√≥pia do arquivo para transcri√ß√£o, j√° que vamos usar a posi√ß√£o original para envio
            current_pos = audio.file.tell()
            audio.file.seek(0)
            audio_copy = io.BytesIO(audio.file.read())
            audio.file.seek(current_pos)

            # Prepara o arquivo para envio
            files.append(File(audio.file, f"{user_id}.{sink.encoding}"))

        # Envia os arquivos de √°udio
        try:
            await channel.send(
                f"Grava√ß√£o finalizada para: {', '.join(recorded_users)}.",
                files=files,
            )

            # Atualiza mensagem de status
            await status_message.edit(
                content="üìÑ Arquivos de √°udio enviados! Iniciando transcri√ß√£o em tempo real..."
            )

            # Inicia transcri√ß√µes em tempo real para cada arquivo
            transcription_tasks = []
            for user_id, audio in sink.audio_data.items():
                # Cria uma c√≥pia do arquivo para transcri√ß√£o
                audio_copy = io.BytesIO()
                audio.file.seek(0)
                audio_copy.write(audio.file.read())
                audio_copy.seek(0)

                # Adiciona a tarefa de transcri√ß√£o √† lista
                task = asyncio.create_task(
                    self.transcribe_audio_live(audio_copy, channel, user_id)
                )
                transcription_tasks.append(task)

            # Aguarda todas as transcri√ß√µes terminarem
            await asyncio.gather(*transcription_tasks)

            # Atualiza a mensagem de status para conclu√≠do
            await status_message.edit(
                content="‚úÖ Processamento de √°udio conclu√≠do!"
            )

            logger.info(
                f"Arquivos de √°udio e transcri√ß√µes enviados para o canal {channel.id}"
            )
        except Exception as e:
            logger.error(f"Erro ao processar √°udio: {e}")
            await status_message.edit(
                content=f"‚ùå Erro ao processar √°udio: {e}"
            )


if __name__ == "__main__":
    """Testa a funcionalidade de transcri√ß√£o com um arquivo de √°udio existente."""
    import argparse
    import asyncio
    import pathlib

    # Configura o parser de argumentos para permitir testar com diferentes arquivos
    parser = argparse.ArgumentParser(
        description="Testa a transcri√ß√£o de √°udio"
    )
    parser.add_argument(
        "--arquivo",
        type=str,
        default=".voice_recordings/439894995890208768.wav",
        help="Caminho para o arquivo de √°udio a ser transcrito",
    )
    parser.add_argument(
        "--modelo",
        type=str,
        default="models/vosk-model-small-pt-0.3",
        help="Caminho para o modelo Vosk a ser utilizado",
    )
    parser.add_argument(
        "--chunk_size",
        type=int,
        default=4000,
        help="Tamanho do chunk para processamento de √°udio",
    )

    args = parser.parse_args()

    # Configura o logger para exibir mensagens durante o teste
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    )

    # Define uma fun√ß√£o para testar a transcri√ß√£o
    async def test_transcription(
        audio_path: str, modelo_path: str, chunk_size: int
    ) -> None:
        """Testa a transcri√ß√£o de um arquivo de √°udio.

        Args:
            audio_path: Caminho para o arquivo de √°udio.
            modelo_path: Caminho para o modelo Vosk.
            chunk_size: Tamanho do chunk para processamento.
        """
        # Verifica se o arquivo existe
        audio_file_path = pathlib.Path(audio_path)
        if not audio_file_path.exists():
            print(f"‚ùå Erro: O arquivo {audio_path} n√£o existe.")
            return

        # Verifica se o modelo existe
        modelo_dir_path = pathlib.Path(modelo_path)
        if not modelo_dir_path.exists():
            print(f"‚ùå Erro: O modelo em {modelo_path} n√£o existe.")
            print(
                "   Voc√™ precisa baixar o modelo Vosk para portugu√™s e extra√≠-lo para este diret√≥rio."
            )
            print(
                "   Download: https://alphacephei.com/vosk/models/vosk-model-small-pt-0.3.zip"
            )
            return

        print(f"üéØ Testando transcri√ß√£o do arquivo: {audio_path}")
        print(f"üß† Usando modelo: {modelo_path}")
        print(f"‚öôÔ∏è Par√¢metros: chunk_size={chunk_size}")

        try:
            # Abre o arquivo como BytesIO para simular o processamento real
            with open(audio_file_path, "rb") as f:
                audio_data = io.BytesIO(f.read())

            # Carrega o modelo Vosk
            model = Model(modelo_path)

            # Abre o arquivo de √°udio com wave
            audio_data.seek(0)
            wf = wave.open(audio_data, "rb")

            # Exibe informa√ß√µes sobre o arquivo de √°udio
            print("\nüìä Informa√ß√µes do arquivo de √°udio:")
            print(f"   Canais: {wf.getnchannels()}")
            print(f"   Width: {wf.getsampwidth()}")
            print(f"   Taxa de amostragem: {wf.getframerate()} Hz")
            print(f"   Frames: {wf.getnframes()}")
            print(
                f"   Dura√ß√£o: {wf.getnframes() / wf.getframerate():.2f} segundos"
            )

            # Configura o reconhecedor
            recognizer = KaldiRecognizer(model, wf.getframerate())
            recognizer.SetWords(True)

            # Medi√ß√£o de tempo para an√°lise de performance
            import time

            start_time = time.time()

            # Processa o √°udio em chunks
            results = []
            total_audio_processed = 0

            print("\nüîÑ Processando √°udio...")

            while True:
                data = wf.readframes(chunk_size)
                if len(data) == 0:
                    break

                total_audio_processed += len(data)

                if recognizer.AcceptWaveform(data):
                    result = json.loads(recognizer.Result())
                    if "text" in result and result["text"]:
                        results.append(result["text"])
                        print(f'   ‚Ü™ Trecho reconhecido: "{result["text"]}"')

            # Obt√©m o resultado final
            final_result = json.loads(recognizer.FinalResult())
            if "text" in final_result and final_result["text"]:
                results.append(final_result["text"])
                print(f'   ‚Ü™ Trecho final: "{final_result["text"]}"')

            # Calcula o tempo de processamento
            elapsed_time = time.time() - start_time

            # Junta todos os resultados
            transcription = " ".join(results)

            print("\n‚úÖ Transcri√ß√£o conclu√≠da!")
            print(f"‚è±Ô∏è Tempo de processamento: {elapsed_time:.2f} segundos")
            print(
                f"üìà Velocidade: {total_audio_processed / elapsed_time / 1024:.2f} KB/s"
            )

            # Exibe a transcri√ß√£o completa
            print("\nüìù Transcri√ß√£o completa:")
            print(f'"{transcription}"')

            # Se n√£o houver transcri√ß√£o, exibe uma mensagem
            if not transcription:
                print("‚ùó Nenhum texto foi reconhecido no √°udio.")

            # Verifica√ß√£o de palavras comuns para an√°lise b√°sica de qualidade
            common_words = [
                "eu",
                "voc√™",
                "ele",
                "ela",
                "n√≥s",
                "eles",
                "sim",
                "n√£o",
                "porque",
                "como",
            ]
            words_in_transcript = set(transcription.lower().split())
            common_words_found = words_in_transcript.intersection(common_words)

            print("\nüìä Estat√≠sticas da transcri√ß√£o:")
            print(f"   Total de palavras: {len(transcription.split())}")
            print(
                f"   Palavras comuns encontradas: {', '.join(common_words_found) if common_words_found else 'nenhuma'}"
            )

        except Exception as e:
            print(f"‚ùå Erro durante a transcri√ß√£o: {str(e)}")
            import traceback

            traceback.print_exc()

    # Executa o teste
    try:
        asyncio.run(
            test_transcription(args.arquivo, args.modelo, args.chunk_size)
        )
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Teste interrompido pelo usu√°rio.")
    except Exception as e:
        print(f"‚ùå Erro inesperado: {str(e)}")
        import traceback

        traceback.print_exc()
